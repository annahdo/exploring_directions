{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8812879",
   "metadata": {},
   "source": [
    "# Steering with previously calculated directions\n",
    "We apply activation addition to steer the generated text into positve and negative concept directions respectively.\n",
    "We evaluate the generated text on coherence and content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9de3f9",
   "metadata": {},
   "source": [
    "### User data\n",
    "You need to specify the current working directory and the huggingface [access token](https://huggingface.co/docs/hub/security-tokens) to use this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4087c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify to your current working directory (the directory where this notebook is )\n",
    "cwd = \"exploring_directions\"\n",
    "\n",
    "# enter your authentication token from huggingface and press enter to access the models\n",
    "auth_token = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoConfig\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff64be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules\n",
    "import sys\n",
    "import importlib\n",
    "# join the path to the modules to the current working directory\n",
    "\n",
    "sys.path.append(os.path.join(cwd, \"modules\"))\n",
    "import wrapping\n",
    "import utils\n",
    "\n",
    "importlib.reload(wrapping)\n",
    "importlib.reload(utils)\n",
    "\n",
    "from wrapping import WrappedModel\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ead65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-2-7b-chat-hf\"\n",
    "model_path = f\"meta-llama/{model_name}\"\n",
    "precision = torch.bfloat16\n",
    "\n",
    "\n",
    "# define directories\n",
    "results_dir = make_dir(os.path.join(cwd, 'results/'))\n",
    "generations_dir = make_dir(os.path.join(results_dir, 'generations/'))\n",
    "plots_dir = make_dir(os.path.join(cwd, 'plots/'))\n",
    "data_dir = make_dir(os.path.join(cwd, 'data/'))\n",
    "\n",
    "# parameters for steering/generation\n",
    "data_file = os.path.join(data_dir, 'test_sentences.txt')\n",
    "num_test_sentences = 500\n",
    "random_seed = 42\n",
    "calc_generations = True\n",
    "block_name = \"decoder_block\"\n",
    "max_new_tokens = 40 # how many tokens to generate while steering\n",
    "layer_ids = [0, 5, 10, 15, 20, 25, 30] # which layers to steer\n",
    "batch_size = 128\n",
    "# directions have different norms for different methods. We need to choose coefficients appropriately\n",
    "# we can take the norms of one method that has relation to actual differences in hidden layers as coefficients for all methods\n",
    "norm_method = \"ClassMeans\"\n",
    "# we use norms of ClassMeans directions as coefficients, but utility is based on differences, so we need to divide by 2 \n",
    "multiplier = 0.5\n",
    "\n",
    "# set to True if you want to evaluate the generated data\n",
    "evaluate_perplexity = True\n",
    "evaluate_sentiment = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7431c42a",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We need some setup to generate sentences. Like the beginning of a scenario, that we then generate the end to while adding a steering vector. We can just get some sentences from the utility test set which are easily divisible into two parts, throw away the second part and use the first part as the generation seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data\n",
    "X_test = load_util_data(data_dir=os.path.join(cwd, 'data/ethics/utilitarianism/'), split='test')\n",
    "X_test, y_test = mix_util_pairs(X_test)\n",
    "\n",
    "test_data_idxs, test_sentences = find_two_sentences(X_test[:, 0], split_str1=\".\", split_str2=\",\", larger_than1=2, larger_than2=1)\n",
    "\n",
    "with open(data_file, \"w\") as f:\n",
    "    for s in test_sentences:\n",
    "        f.write(s + \" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(data_file, 'r') as f:\n",
    "    test_sentences = [line.strip() for line in f]\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "idxs = np.random.choice(len(test_sentences), num_test_sentences, replace=False)\n",
    "test_sentences = [test_sentences[idx] for idx in idxs]\n",
    "for i in range(10):\n",
    "    print(test_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c958a10",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, token=auth_token, device_map=\"auto\").to(device=device, dtype=precision)\n",
    "model.eval()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, token=auth_token, device_map=\"auto\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left' \n",
    "\n",
    "num_hidden_layers = model.config.num_hidden_layers\n",
    "hidden_size = model.config.hidden_size\n",
    "\n",
    "# create wrapped model\n",
    "wrapped_model = WrappedModel(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3441078",
   "metadata": {},
   "source": [
    "# Steering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b57f7",
   "metadata": {},
   "source": [
    "### Load directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faaca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pkl directions\n",
    "with open(os.path.join(results_dir, f'directions_{model_name}.pkl'), \"rb\") as f:\n",
    "    all_directions = pickle.load(f)\n",
    "\n",
    "# remove random directions\n",
    "if \"Random\" in all_directions:\n",
    "    all_directions.pop(\"Random\", None)\n",
    "\n",
    "method_names = list(all_directions.keys())\n",
    "print(method_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b9d632",
   "metadata": {},
   "source": [
    "### Define multipliers for scaling the steering vectors\n",
    "We need to define the scaling coefficient for each layer separately. We can take the norms of one method that has relation to actual differences in hidden layers as coefficients for all methods for example the class means method. As the class mean norm would be the difference between high utility and low utility examples but we are starting from neutral, we multiply by 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_directions = all_directions[norm_method]\n",
    "# convert dict to tensor\n",
    "norm_directions = {k: torch.tensor(v).to(device=device, dtype=precision) for k, v in norm_directions.items()}\n",
    "\n",
    "coeffs = {k:multiplier*v.norm().squeeze() for k, v in norm_directions.items()}\n",
    "\n",
    "\n",
    "# make data frame for coefficients\n",
    "df_coeffs = pd.DataFrame.from_dict({k: v.item() for k, v in coeffs.items()}, orient='index', columns=['coeff'])\n",
    "df_coeffs.plot(kind='line', marker='o', figsize=(8, 5))\n",
    "\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel(f\"Norm '{norm_method}'\")\n",
    "plt.grid(True)\n",
    "# switch off legend\n",
    "plt.legend().set_visible(False)\n",
    "\n",
    "plt.savefig(os.path.join(plots_dir, f\"norm_{norm_method}_{model_name}.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c66279",
   "metadata": {},
   "source": [
    "### Completion with activation addition\n",
    "\n",
    "We add the scaled steering vectors for each method and layer seperately in the positive and negative direction respectively and generate new tokens for each starting sentence in `test_sentences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_generations:\n",
    "    \n",
    "    # completions without activation steering\n",
    "    generations = []\n",
    "    wrapped_model.unwrap()\n",
    "    for sentence_batch in batchify(test_sentences, batch_size):\n",
    "        generated = wrapped_model.generate(sentence_batch, max_new_tokens=max_new_tokens, use_cache=True)\n",
    "        generations.extend(generated)\n",
    "\n",
    "    # save generations as text files\n",
    "    with open(os.path.join(generations_dir, f\"generations_neutral.txt\"), \"w\") as f:\n",
    "        for item in generations:\n",
    "            # remove newline characters\n",
    "            item = item.replace(\"\\n\", \" \")\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "    for method_name in method_names:\n",
    "        \n",
    "        print(f\"method: {method_name}\")\n",
    "\n",
    "        for layer_id in tqdm(layer_ids):\n",
    "\n",
    "            generations = {\"positive\": [], \"negative\": []}\n",
    "\n",
    "            wrapped_model.unwrap()\n",
    "            wrapped_model.wrap_block(layer_id, block_name=block_name)\n",
    "\n",
    "            direction = torch.tensor(all_directions[method_name][layer_id]).to(device=device, dtype=precision)\n",
    "            direction = direction / direction.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            wrapped_model.reset()\n",
    "            wrapped_model.set_to_add(layer_id, coeffs[layer_id]*direction, block_name=block_name)\n",
    "\n",
    "            for sentence_batch in batchify(test_sentences, batch_size):\n",
    "                generated = wrapped_model.generate(sentence_batch, max_new_tokens=max_new_tokens, use_cache=True)\n",
    "                generations[\"positive\"].extend(generated)\n",
    "\n",
    "\n",
    "            wrapped_model.reset()\n",
    "            wrapped_model.set_to_add(layer_id, -coeffs[layer_id]*direction, block_name=block_name)\n",
    "\n",
    "            for sentence_batch in batchify(test_sentences, batch_size):\n",
    "                generated = wrapped_model.generate(sentence_batch, max_new_tokens=max_new_tokens, use_cache=True)\n",
    "                generations[\"negative\"].extend(generated)\n",
    "\n",
    "            # save generations as text files\n",
    "            with open(os.path.join(generations_dir, f\"generations_positive_{method_name}_{layer_id}.txt\"), \"w\") as f:\n",
    "                for item in generations[\"positive\"]:\n",
    "                    # remove newline characters\n",
    "                    item = item.replace(\"\\n\", \" \")\n",
    "                    f.write(\"%s\\n\" % item)\n",
    "\n",
    "            with open(os.path.join(generations_dir, f\"generations_negative_{method_name}_{layer_id}.txt\"), \"w\") as f:\n",
    "                for item in generations[\"negative\"]:\n",
    "                    item = item.replace(\"\\n\", \" \")\n",
    "                    f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93245c",
   "metadata": {},
   "source": [
    "# Calculate perplexity to evaluate the coherence of the generated text\n",
    "\n",
    "Using the original (non-steered) model, we sum over the log probability of each generated sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad15464",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model.unwrap()\n",
    "batch_size = 32\n",
    "\n",
    "if evaluate_perplexity:\n",
    "    perplexities = {}\n",
    "\n",
    "    # calculate perplexities for positive and negative generations\n",
    "    for method_name in method_names:\n",
    "        perplexities[method_name] = {}\n",
    "        print(f\"method: {method_name}\")\n",
    "        for layer_id in tqdm(layer_ids):\n",
    "            gc.collect()\n",
    "\n",
    "            # check if file exists\n",
    "            if not os.path.exists(os.path.join(generations_dir, f\"generations_positive_{method_name}_{layer_id}.txt\")):\n",
    "                print(f\"File not found: {os.path.join(generations_dir, f'generations_positive_{method_name}_{layer_id}.txt')}\")\n",
    "                continue\n",
    "\n",
    "            # load generations\n",
    "            all_generations = load_generations(os.path.join(generations_dir, f\"generations_positive_{method_name}_{layer_id}.txt\"))\n",
    "            all_generations.extend(load_generations(os.path.join(generations_dir, f\"generations_negative_{method_name}_{layer_id}.txt\")))\n",
    "\n",
    "            perplexities[method_name][layer_id] = eval_perplexity(all_generations, batch_size, tokenizer, wrapped_model, device)\n",
    "\n",
    "    # calculate perplexities for test set\n",
    "    print(f\"method: TestSet\")\n",
    "    perplexities['TestSet'] = {}\n",
    "    perp = eval_perplexity(list(np.concatenate([X_test[:,0], X_test[:,1]])), batch_size, tokenizer, wrapped_model, device)\n",
    "    for layer_id in layer_ids:\n",
    "        perplexities['TestSet'][layer_id] = perp  \n",
    "\n",
    "    # calculate perplexities for neutral generations\n",
    "    print(f\"method: NoSteering\")\n",
    "    perplexities['NoSteering'] = {}  \n",
    "    all_generations = load_generations(os.path.join(generations_dir, f\"generations_neutral.txt\"))\n",
    "    perp = eval_perplexity(all_generations, batch_size, tokenizer, wrapped_model, device)\n",
    "    for layer_id in layer_ids:\n",
    "        perplexities['NoSteering'][layer_id] = perp\n",
    " \n",
    "    # save perplexities\n",
    "    with open(os.path.join(results_dir, f'perplexity_{model_name}.pkl'), \"wb\") as f:\n",
    "        pickle.dump(perplexities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4aa38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load probs\n",
    "with open(os.path.join(results_dir, f'perplexity_{model_name}.pkl'), \"rb\") as f:\n",
    "    probs = pickle.load(f)\n",
    "plot_lines(probs, \"Perplexity\", os.path.join(plots_dir, f\"perplexity_{model_name}.png\"), method_names=probs.keys(), loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8533e",
   "metadata": {},
   "source": [
    "# Sentiment analysis with sentiment model\n",
    "\n",
    "We do sentiment analysis with a classifier based on the RoBERTa model. There are three output classes: negative, neutral and positive. We focus on the probability for the positive output check that positively steered generated text has higher positive output than negatively steered generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_path = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_path)\n",
    "sentiment_tokenizer.pad_token = tokenizer.eos_token\n",
    "sentiment_tokenizer.padding_side = 'left' \n",
    "config = AutoConfig.from_pretrained(sentiment_model_path)\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_path).to(device=device, dtype=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "if evaluate_sentiment:\n",
    "    sentiment_accs = {}\n",
    "\n",
    "    for method_name in method_names:\n",
    "        gc.collect()\n",
    "        sentiment_accs[method_name] = {}\n",
    "        print(f\"method: {method_name}\")\n",
    "        for layer_id in tqdm(layer_ids):\n",
    "            gc.collect()\n",
    "\n",
    "            # check if file exists\n",
    "            if not os.path.exists(os.path.join(generations_dir, f\"generations_positive_{method_name}_{layer_id}.txt\")):\n",
    "                print(f\"File not found: {os.path.join(generations_dir, f'generations_positive_{method_name}_{layer_id}.txt')}\")\n",
    "                continue\n",
    "\n",
    "            # load generations\n",
    "            generations = {\"positive\": [], \"negative\": []}\n",
    "            generations[\"positive\"] = load_generations(os.path.join(generations_dir, f\"generations_positive_{method_name}_{layer_id}.txt\"))\n",
    "            generations[\"negative\"] = load_generations(os.path.join(generations_dir, f\"generations_negative_{method_name}_{layer_id}.txt\"))\n",
    "\n",
    "            sentiment_accs[method_name][layer_id] = eval_sentiment(generations, batch_size, sentiment_tokenizer, sentiment_model, device)\n",
    "\n",
    "    # calculate sentiment for test set\n",
    "    print(f\"method: TestSet\")\n",
    "    sentiment_accs['TestSet'] = {}\n",
    "    generations = {\"positive\": [], \"negative\": []}\n",
    "    generations[\"positive\"] = list(np.concatenate([X_test[y_test==1, 0], X_test[y_test==0, 1]]))\n",
    "    generations[\"negative\"] = list(np.concatenate([X_test[y_test==1, 1], X_test[y_test==0, 0]]))\n",
    "\n",
    "\n",
    "    accs = eval_sentiment(generations, batch_size, sentiment_tokenizer, sentiment_model, device)\n",
    "    for layer_id in layer_ids:\n",
    "        sentiment_accs['TestSet'][layer_id] = accs\n",
    "                                   \n",
    "    # save accs\n",
    "    with open(os.path.join(results_dir, f'sentiment_accs_{model_name}.pkl'), \"wb\") as f:\n",
    "        pickle.dump(sentiment_accs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ae0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sentiment_accs\n",
    "with open(os.path.join(results_dir, f'sentiment_accs_{model_name}.pkl'), \"rb\") as f:\n",
    "    sentiment_accs = pickle.load(f)\n",
    "plot_lines(sentiment_accs, \"Sentiment accuracy\", os.path.join(plots_dir, f\"sentiment_accs_{model_name}.png\"), method_names=sentiment_accs.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
